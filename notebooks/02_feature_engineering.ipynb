{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering (Özellik Mühendisliği)\n",
    "\n",
    "Bu notebook'ta model için yeni özellikler türeteceğiz.\n",
    "\n",
    "**Amaçlar:**\n",
    "- Kategorik değişkenleri encode etmek\n",
    "- Sayısal değişkenleri normalize etmek\n",
    "- Yeni türetilmiş özellikler oluşturmak\n",
    "- Risk skorları hesaplamak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.loader import DataLoader\n",
    "from src.data.preprocessor import DataPreprocessor\n",
    "from src.features.engineer import FeatureEngineer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Veri Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_dir='../data')\n",
    "\n",
    "try:\n",
    "    df = loader.load_customer_360()\n",
    "    print(\"Loaded from database\")\n",
    "except:\n",
    "    df = loader.load_telco_churn()\n",
    "    print(\"Loaded from CSV\")\n",
    "\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Clean data\n",
    "df_cleaned = preprocessor.clean_data(df)\n",
    "print(\"Data cleaned\")\n",
    "\n",
    "# Handle missing values\n",
    "df_cleaned = preprocessor.handle_missing_values(df_cleaned)\n",
    "print(\"Missing values handled\")\n",
    "\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "engineer = FeatureEngineer()\n",
    "\n",
    "# Create all features\n",
    "df_features = engineer.create_all_features(df_cleaned)\n",
    "\n",
    "print(f\"Original columns: {len(df_cleaned.columns)}\")\n",
    "print(f\"After feature engineering: {len(df_features.columns)}\")\n",
    "print(f\"\\nNew features created: {len(df_features.columns) - len(df_cleaned.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List new features\n",
    "new_features = engineer.get_feature_list()\n",
    "print(\"Engineered Features:\")\n",
    "for i, feat in enumerate(new_features, 1):\n",
    "    if feat in df_features.columns:\n",
    "        print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample of engineered features\n",
    "feature_cols = ['customer_id', 'tenure_group', 'is_new_customer', 'is_loyal_customer',\n",
    "                'avg_monthly_charge', 'service_count', 'has_premium_support',\n",
    "                'contract_risk_score', 'payment_risk_score', 'combined_risk_score']\n",
    "\n",
    "available_cols = [c for c in feature_cols if c in df_features.columns]\n",
    "df_features[available_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Risk Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk score distribution\n",
    "if 'combined_risk_score' in df_features.columns:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Contract risk\n",
    "    df_features['contract_risk_score'].hist(ax=axes[0], bins=10, edgecolor='black')\n",
    "    axes[0].set_title('Contract Risk Score Distribution')\n",
    "    \n",
    "    # Payment risk\n",
    "    df_features['payment_risk_score'].hist(ax=axes[1], bins=10, edgecolor='black')\n",
    "    axes[1].set_title('Payment Risk Score Distribution')\n",
    "    \n",
    "    # Combined risk\n",
    "    df_features['combined_risk_score'].hist(ax=axes[2], bins=10, edgecolor='black')\n",
    "    axes[2].set_title('Combined Risk Score Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk score vs Churn\n",
    "churn_col = 'churned' if 'churned' in df_features.columns else 'Churn'\n",
    "\n",
    "if 'combined_risk_score' in df_features.columns and churn_col in df_features.columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Box plot\n",
    "    df_features.boxplot(column='combined_risk_score', by=churn_col)\n",
    "    plt.title('Combined Risk Score by Churn Status')\n",
    "    plt.suptitle('')\n",
    "    plt.ylabel('Risk Score')\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistics\n",
    "    print(\"\\nRisk Score Statistics:\")\n",
    "    print(df_features.groupby(churn_col)['combined_risk_score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Service Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service count distribution\n",
    "if 'service_count' in df_features.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Distribution\n",
    "    df_features['service_count'].value_counts().sort_index().plot(kind='bar', ax=axes[0])\n",
    "    axes[0].set_title('Service Count Distribution')\n",
    "    axes[0].set_xlabel('Number of Services')\n",
    "    \n",
    "    # Churn rate by service count\n",
    "    churn_by_services = df_features.groupby('service_count')[churn_col].mean() * 100\n",
    "    churn_by_services.plot(kind='bar', ax=axes[1], color='coral')\n",
    "    axes[1].set_title('Churn Rate by Service Count')\n",
    "    axes[1].set_ylabel('Churn Rate (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df_encoded = preprocessor.encode_categorical(df_features, fit=True)\n",
    "\n",
    "# View encoded columns\n",
    "encoded_cols = [c for c in df_encoded.columns if '_encoded' in c]\n",
    "print(f\"Encoded columns: {encoded_cols}\")\n",
    "\n",
    "df_encoded[encoded_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Scaling Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "df_scaled = preprocessor.scale_numeric(df_encoded, fit=True)\n",
    "\n",
    "# View scaled columns\n",
    "scaled_cols = [c for c in df_scaled.columns if '_scaled' in c]\n",
    "print(f\"Scaled columns: {scaled_cols}\")\n",
    "\n",
    "df_scaled[scaled_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with churn\n",
    "numeric_df = df_scaled.select_dtypes(include=[np.number])\n",
    "\n",
    "if churn_col in numeric_df.columns or 'churned' in df_scaled.columns:\n",
    "    # Ensure churn is numeric\n",
    "    if churn_col not in numeric_df.columns:\n",
    "        numeric_df[churn_col] = df_scaled[churn_col].astype(int)\n",
    "    \n",
    "    correlations = numeric_df.corr()[churn_col].sort_values(ascending=False)\n",
    "    \n",
    "    # Top positive and negative correlations\n",
    "    print(\"Top 10 Features Positively Correlated with Churn:\")\n",
    "    print(correlations.head(10))\n",
    "    \n",
    "    print(\"\\nTop 10 Features Negatively Correlated with Churn:\")\n",
    "    print(correlations.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_corr = correlations.drop(churn_col).abs().sort_values(ascending=False).head(15)\n",
    "correlations[top_corr.index].plot(kind='barh')\n",
    "plt.title('Feature Correlations with Churn')\n",
    "plt.xlabel('Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "output_path = loader.save_to_csv(df_scaled, 'processed_features.csv', directory='processed')\n",
    "print(f\"Saved to: {output_path}\")\n",
    "print(f\"Shape: {df_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\" * 50)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original Features: {len(df.columns)}\")\n",
    "print(f\"Total Features: {len(df_scaled.columns)}\")\n",
    "print(f\"Encoded Features: {len(encoded_cols)}\")\n",
    "print(f\"Scaled Features: {len(scaled_cols)}\")\n",
    "print(f\"Engineered Features: {len(new_features)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
